Index: kernel-rpi-6_1/drivers/dma-buf/dma-fence-array.c
===================================================================
--- kernel-rpi-6_1.orig/drivers/dma-buf/dma-fence-array.c
+++ kernel-rpi-6_1/drivers/dma-buf/dma-fence-array.c
@@ -103,36 +103,10 @@ static bool dma_fence_array_enable_signa
 static bool dma_fence_array_signaled(struct dma_fence *fence)
 {
 	struct dma_fence_array *array = to_dma_fence_array(fence);
-	int num_pending;
-	unsigned int i;
 
-	/*
-	 * We need to read num_pending before checking the enable_signal bit
-	 * to avoid racing with the enable_signaling() implementation, which
-	 * might decrement the counter, and cause a partial check.
-	 * atomic_read_acquire() pairs with atomic_dec_and_test() in
-	 * dma_fence_array_enable_signaling()
-	 *
-	 * The !--num_pending check is here to account for the any_signaled case
-	 * if we race with enable_signaling(), that means the !num_pending check
-	 * in the is_signalling_enabled branch might be outdated (num_pending
-	 * might have been decremented), but that's fine. The user will get the
-	 * right value when testing again later.
-	 */
-	num_pending = atomic_read_acquire(&array->num_pending);
-	if (test_bit(DMA_FENCE_FLAG_ENABLE_SIGNAL_BIT, &array->base.flags)) {
-		if (num_pending <= 0)
-			goto signal;
+	if (atomic_read(&array->num_pending) > 0)
 		return false;
-	}
 
-	for (i = 0; i < array->num_fences; ++i) {
-		if (dma_fence_is_signaled(array->fences[i]) && !--num_pending)
-			goto signal;
-	}
-	return false;
-
-signal:
 	dma_fence_array_clear_pending_error(array);
 	return true;
 }
Index: kernel-rpi-6_1/drivers/dma-buf/dma-fence-unwrap.c
===================================================================
--- kernel-rpi-6_1.orig/drivers/dma-buf/dma-fence-unwrap.c
+++ kernel-rpi-6_1/drivers/dma-buf/dma-fence-unwrap.c
@@ -12,7 +12,6 @@
 #include <linux/dma-fence-chain.h>
 #include <linux/dma-fence-unwrap.h>
 #include <linux/slab.h>
-#include <linux/sort.h>
 
 /* Internal helper to start new array iteration, don't use directly */
 static struct dma_fence *
@@ -60,25 +59,6 @@ struct dma_fence *dma_fence_unwrap_next(
 }
 EXPORT_SYMBOL_GPL(dma_fence_unwrap_next);
 
-
-static int fence_cmp(const void *_a, const void *_b)
-{
-	struct dma_fence *a = *(struct dma_fence **)_a;
-	struct dma_fence *b = *(struct dma_fence **)_b;
-
-	if (a->context < b->context)
-		return -1;
-	else if (a->context > b->context)
-		return 1;
-
-	if (dma_fence_is_later(b, a))
-		return 1;
-	else if (dma_fence_is_later(a, b))
-		return -1;
-
-	return 0;
-}
-
 /* Implementation for the dma_fence_merge() marco, don't use directly */
 struct dma_fence *__dma_fence_unwrap_merge(unsigned int num_fences,
 					   struct dma_fence **fences,
@@ -87,7 +67,8 @@ struct dma_fence *__dma_fence_unwrap_mer
 	struct dma_fence_array *result;
 	struct dma_fence *tmp, **array;
 	ktime_t timestamp;
-	int i, j, count;
+	unsigned int i;
+	size_t count;
 
 	count = 0;
 	timestamp = ns_to_ktime(0);
@@ -115,55 +96,78 @@ struct dma_fence *__dma_fence_unwrap_mer
 	if (!array)
 		return NULL;
 
+	/*
+	 * This trashes the input fence array and uses it as position for the
+	 * following merge loop. This works because the dma_fence_merge()
+	 * wrapper macro is creating this temporary array on the stack together
+	 * with the iterators.
+	 */
+	for (i = 0; i < num_fences; ++i)
+		fences[i] = dma_fence_unwrap_first(fences[i], &iter[i]);
+
 	count = 0;
-	for (i = 0; i < num_fences; ++i) {
-		dma_fence_unwrap_for_each(tmp, &iter[i], fences[i]) {
-			if (!dma_fence_is_signaled(tmp)) {
-				array[count++] = dma_fence_get(tmp);
-			} else {
-				ktime_t t = dma_fence_timestamp(tmp);
+	do {
+		unsigned int sel;
 
-				if (ktime_after(t, timestamp))
-					timestamp = t;
+restart:
+		tmp = NULL;
+		for (i = 0; i < num_fences; ++i) {
+			struct dma_fence *next;
+
+			while (fences[i] && dma_fence_is_signaled(fences[i]))
+				fences[i] = dma_fence_unwrap_next(&iter[i]);
+
+			next = fences[i];
+			if (!next)
+				continue;
+
+			/*
+			 * We can't guarantee that inpute fences are ordered by
+			 * context, but it is still quite likely when this
+			 * function is used multiple times. So attempt to order
+			 * the fences by context as we pass over them and merge
+			 * fences with the same context.
+			 */
+			if (!tmp || tmp->context > next->context) {
+				tmp = next;
+				sel = i;
+
+			} else if (tmp->context < next->context) {
+				continue;
+
+			} else if (dma_fence_is_later(tmp, next)) {
+				fences[i] = dma_fence_unwrap_next(&iter[i]);
+				goto restart;
+			} else {
+				fences[sel] = dma_fence_unwrap_next(&iter[sel]);
+				goto restart;
 			}
 		}
-	}
 
-	if (count == 0 || count == 1)
-		goto return_fastpath;
-
-	sort(array, count, sizeof(*array), fence_cmp, NULL);
+		if (tmp) {
+			array[count++] = dma_fence_get(tmp);
+			fences[sel] = dma_fence_unwrap_next(&iter[sel]);
+		}
+	} while (tmp);
 
-	/*
-	 * Only keep the most recent fence for each context.
-	 */
-	j = 0;
-	for (i = 1; i < count; i++) {
-		if (array[i]->context == array[j]->context)
-			dma_fence_put(array[i]);
-		else
-			array[++j] = array[i];
+	if (count == 0) {
+		tmp = dma_fence_allocate_private_stub(ktime_get());
+		goto return_tmp;
 	}
-	count = ++j;
 
-	if (count > 1) {
-		result = dma_fence_array_create(count, array,
-						dma_fence_context_alloc(1),
-						1, false);
-		if (!result) {
-			for (i = 0; i < count; i++)
-				dma_fence_put(array[i]);
-			tmp = NULL;
-			goto return_tmp;
-		}
-		return &result->base;
+	if (count == 1) {
+		tmp = array[0];
+		goto return_tmp;
 	}
 
-return_fastpath:
-	if (count == 0)
-		tmp = dma_fence_allocate_private_stub(timestamp);
-	else
-		tmp = array[0];
+	result = dma_fence_array_create(count, array,
+					dma_fence_context_alloc(1),
+					1, false);
+	if (!result) {
+		tmp = NULL;
+		goto return_tmp;
+	}
+	return &result->base;
 
 return_tmp:
 	kfree(array);
Index: kernel-rpi-6_1/drivers/dma-buf/heaps/cma_heap.c
===================================================================
--- kernel-rpi-6_1.orig/drivers/dma-buf/heaps/cma_heap.c
+++ kernel-rpi-6_1/drivers/dma-buf/heaps/cma_heap.c
@@ -165,7 +165,7 @@ static vm_fault_t cma_heap_vm_fault(stru
 	struct vm_area_struct *vma = vmf->vma;
 	struct cma_heap_buffer *buffer = vma->vm_private_data;
 
-	if (vmf->pgoff >= buffer->pagecount)
+	if (vmf->pgoff > buffer->pagecount)
 		return VM_FAULT_SIGBUS;
 
 	vmf->page = buffer->pages[vmf->pgoff];
Index: kernel-rpi-6_1/drivers/dma-buf/heaps/system_heap.c
===================================================================
--- kernel-rpi-6_1.orig/drivers/dma-buf/heaps/system_heap.c
+++ kernel-rpi-6_1/drivers/dma-buf/heaps/system_heap.c
@@ -54,11 +54,6 @@ static gfp_t order_flags[] = {HIGH_ORDER
 static const unsigned int orders[] = {8, 4, 0};
 #define NUM_ORDERS ARRAY_SIZE(orders)
 
-static unsigned int module_max_order = orders[0];
-
-module_param_named(max_order, module_max_order, uint, 0400);
-MODULE_PARM_DESC(max_order, "Maximum allocation order override.");
-
 static struct sg_table *dup_sg_table(struct sg_table *table)
 {
 	struct sg_table *new_table;
@@ -344,7 +339,7 @@ static struct dma_buf *system_heap_alloc
 	struct system_heap_buffer *buffer;
 	DEFINE_DMA_BUF_EXPORT_INFO(exp_info);
 	unsigned long size_remaining = len;
-	unsigned int max_order = module_max_order;
+	unsigned int max_order = orders[0];
 	struct dma_buf *dmabuf;
 	struct sg_table *table;
 	struct scatterlist *sg;
@@ -438,9 +433,6 @@ static int system_heap_create(void)
 	if (IS_ERR(sys_heap))
 		return PTR_ERR(sys_heap);
 
-	if (module_max_order > orders[0])
-		module_max_order = orders[0];
-
 	return 0;
 }
 module_init(system_heap_create);
Index: kernel-rpi-6_1/drivers/dma-buf/st-dma-fence-chain.c
===================================================================
--- kernel-rpi-6_1.orig/drivers/dma-buf/st-dma-fence-chain.c
+++ kernel-rpi-6_1/drivers/dma-buf/st-dma-fence-chain.c
@@ -476,9 +476,10 @@ static int find_race(void *arg)
 	for (i = 0; i < ncpus; i++) {
 		int ret;
 
-		ret = kthread_stop_put(threads[i]);
+		ret = kthread_stop(threads[i]);
 		if (ret && !err)
 			err = ret;
+		put_task_struct(threads[i]);
 	}
 	kfree(threads);
 
@@ -590,7 +591,8 @@ static int wait_forward(void *arg)
 	for (i = 0; i < fc.chain_length; i++)
 		dma_fence_signal(fc.fences[i]);
 
-	err = kthread_stop_put(tsk);
+	err = kthread_stop(tsk);
+	put_task_struct(tsk);
 
 err:
 	fence_chains_fini(&fc);
@@ -619,7 +621,8 @@ static int wait_backward(void *arg)
 	for (i = fc.chain_length; i--; )
 		dma_fence_signal(fc.fences[i]);
 
-	err = kthread_stop_put(tsk);
+	err = kthread_stop(tsk);
+	put_task_struct(tsk);
 
 err:
 	fence_chains_fini(&fc);
@@ -666,7 +669,8 @@ static int wait_random(void *arg)
 	for (i = 0; i < fc.chain_length; i++)
 		dma_fence_signal(fc.fences[i]);
 
-	err = kthread_stop_put(tsk);
+	err = kthread_stop(tsk);
+	put_task_struct(tsk);
 
 err:
 	fence_chains_fini(&fc);
Index: kernel-rpi-6_1/drivers/dma-buf/st-dma-fence.c
===================================================================
--- kernel-rpi-6_1.orig/drivers/dma-buf/st-dma-fence.c
+++ kernel-rpi-6_1/drivers/dma-buf/st-dma-fence.c
@@ -540,12 +540,6 @@ static int race_signal_callback(void *ar
 			t[i].before = pass;
 			t[i].task = kthread_run(thread_signal_callback, &t[i],
 						"dma-fence:%d", i);
-			if (IS_ERR(t[i].task)) {
-				ret = PTR_ERR(t[i].task);
-				while (--i >= 0)
-					kthread_stop_put(t[i].task);
-				return ret;
-			}
 			get_task_struct(t[i].task);
 		}
 
@@ -554,9 +548,11 @@ static int race_signal_callback(void *ar
 		for (i = 0; i < ARRAY_SIZE(t); i++) {
 			int err;
 
-			err = kthread_stop_put(t[i].task);
+			err = kthread_stop(t[i].task);
 			if (err && !ret)
 				ret = err;
+
+			put_task_struct(t[i].task);
 		}
 	}
 
Index: kernel-rpi-6_1/drivers/dma-buf/sync_debug.c
===================================================================
--- kernel-rpi-6_1.orig/drivers/dma-buf/sync_debug.c
+++ kernel-rpi-6_1/drivers/dma-buf/sync_debug.c
@@ -110,12 +110,12 @@ static void sync_print_obj(struct seq_fi
 
 	seq_printf(s, "%s: %d\n", obj->name, obj->value);
 
-	spin_lock(&obj->lock); /* Caller already disabled IRQ. */
+	spin_lock_irq(&obj->lock);
 	list_for_each(pos, &obj->pt_list) {
 		struct sync_pt *pt = container_of(pos, struct sync_pt, link);
 		sync_print_fence(s, &pt->base, false);
 	}
-	spin_unlock(&obj->lock);
+	spin_unlock_irq(&obj->lock);
 }
 
 static void sync_print_sync_file(struct seq_file *s,
Index: kernel-rpi-6_1/drivers/dma-buf/udmabuf.c
===================================================================
--- kernel-rpi-6_1.orig/drivers/dma-buf/udmabuf.c
+++ kernel-rpi-6_1/drivers/dma-buf/udmabuf.c
@@ -35,13 +35,12 @@ static vm_fault_t udmabuf_vm_fault(struc
 	struct vm_area_struct *vma = vmf->vma;
 	struct udmabuf *ubuf = vma->vm_private_data;
 	pgoff_t pgoff = vmf->pgoff;
-	unsigned long pfn;
 
 	if (pgoff >= ubuf->pagecount)
 		return VM_FAULT_SIGBUS;
-
-	pfn = page_to_pfn(ubuf->pages[pgoff]);
-	return vmf_insert_pfn(vma, vmf->address, pfn);
+	vmf->page = ubuf->pages[pgoff];
+	get_page(vmf->page);
+	return 0;
 }
 
 static const struct vm_operations_struct udmabuf_vm_ops = {
@@ -57,7 +56,6 @@ static int mmap_udmabuf(struct dma_buf *
 
 	vma->vm_ops = &udmabuf_vm_ops;
 	vma->vm_private_data = ubuf;
-	vm_flags_set(vma, VM_PFNMAP | VM_DONTEXPAND | VM_DONTDUMP);
 	return 0;
 }
 
@@ -194,7 +192,7 @@ static const struct dma_buf_ops udmabuf_
 };
 
 #define SEALS_WANTED (F_SEAL_SHRINK)
-#define SEALS_DENIED (F_SEAL_WRITE|F_SEAL_FUTURE_WRITE)
+#define SEALS_DENIED (F_SEAL_WRITE)
 
 static long udmabuf_create(struct miscdevice *device,
 			   struct udmabuf_create_list *head,
